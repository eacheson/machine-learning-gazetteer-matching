{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning gazetteer matching: learning curve\n",
    "Notebook showing one run testing how performance changes when we increase the training set size (40 pairs at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "from gazmatch import matchutils as mu\n",
    "from gazmatch import mlrunner as ml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PATHS ###\n",
    "data_dir = 'data'\n",
    "path_geonames_csv = os.path.join(data_dir, 'geonames_ch_swisscoords.csv')\n",
    "path_swissnames_csv = os.path.join(data_dir, 'swissnames_new_uuids.csv')\n",
    "path_test_set_ids = os.path.join(data_dir, 'test_set_ids.pkl')\n",
    "# with original UUIDs\n",
    "path_ground_truth_list = os.path.join(data_dir, 'ground_truth_flat.pkl')\n",
    "# modified record-unique IDs\n",
    "path_ground_truth_dict_new_uuids = os.path.join(data_dir, 'ground_truth_new_uuids.pkl')\n",
    "path_ground_truth_list_new_uuids = os.path.join(data_dir, 'ground_truth_flat_new_uuids.pkl')\n",
    "# landcover data\n",
    "land_cover_dir = 'ArealStatistik\\\\arealstatistik_nolc_2004\\\\rawdata\\\\stand_20130918_endstand'\n",
    "land_cover_csv = 'AREA_NOLC04_27_130918.csv'\n",
    "\n",
    "# candidate selection: matches per train and test record\n",
    "M_train = 30\n",
    "M_test = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-time data preparation\n",
    "- Prepare the landcover data\n",
    "- Read in the two gazetteers\n",
    "- Read in ground truth data\n",
    "- Do initial training set\n",
    "- Prepare the test data since it's always the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4128498, 13)\n"
     ]
    }
   ],
   "source": [
    "# land cover data\n",
    "df_areal = pd.read_csv(os.path.join(data_dir, land_cover_dir, land_cover_csv), sep=';', encoding='utf-8', low_memory=False)\n",
    "print(df_areal.shape)\n",
    "# prepare for Nearest Neighbour searches (this takes a while!)\n",
    "neighbour_obj = mu.prepare_neighbours(df_areal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 313562 records in SwissNames3D in 21 columns.\n",
      "We have 67796 records in GeoNames in 21 columns.\n",
      "Our ground truth dict has 400 GeoNames records.\n",
      "Our fixed test set has 80 GeoNames records.\n"
     ]
    }
   ],
   "source": [
    "# load SwissNames3D augmented with lat, lons\n",
    "swissnames = pd.read_csv(path_swissnames_csv, sep='\\t', encoding='utf-8', low_memory=False)\n",
    "print(\"We have %s records in SwissNames3D in %s columns.\" %(swissnames.shape[0], swissnames.shape[1]))\n",
    "\n",
    "# load GeoNames with all WGS84 lat, lons projected to swiss coordinates\n",
    "geonames = pd.read_csv(path_geonames_csv, sep='\\t', encoding='utf-8', low_memory=False)\n",
    "print(\"We have %s records in GeoNames in %s columns.\" %(geonames.shape[0], geonames.shape[1]))\n",
    "\n",
    "# ground truth (i.e. positive matches for each geonames record)\n",
    "ground_truth_dict = mu.load_data(path_ground_truth_dict_new_uuids)\n",
    "# sanity check - this should be 400\n",
    "print(\"Our ground truth dict has %s GeoNames records.\" %len(ground_truth_dict))\n",
    "\n",
    "# geonames IDs in our fixed, balanced test set\n",
    "test_gn_ids = mu.load_data(path_test_set_ids)\n",
    "# sanity check - this should be 80\n",
    "print(\"Our fixed test set has %s GeoNames records.\" %len(test_gn_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 320 GeoNames records to potentially use in our training data.\n"
     ]
    }
   ],
   "source": [
    "# must take the test set ids out of consideration\n",
    "potential_training_ids = set(ground_truth_dict.keys()) - test_gn_ids\n",
    "print(\"We have %s GeoNames records to potentially use in our training data.\" %len(potential_training_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 106 positive matches and 1 records with no match\n",
      "Processing record 0...\n",
      "Processing record 50...\n",
      "We had 92 positive and 2302 negative pairs retained in candidate selection.\n",
      "We kept 92 out of a possible 106 positive pairs, i.e. 0.868 (upper bound on recall).\n",
      "Test set: the ratio of neg to pos is 25.022\n",
      "Calculating point-to-point distance between matches...\n",
      "Calculating Levenshtein distance between names...\n",
      "Calculating Levenshtein distance between de-commaed names...\n",
      "Calculating min Levenshtein distance on alternate names...\n",
      "Getting the min Levenshtein distance overall...\n",
      "Calculating the normalized Levenshtein-Damerau distance...\n",
      "Calculating Jaro similarity...\n",
      "Calculating Jaro-Winkler similarity...\n",
      "Getting the absolute elevation distance...\n",
      "Getting the feature types from both gazetteers...\n",
      "Getting the dummy variables for feature types...\n",
      "Getting the landcover classes for source and target...\n",
      "Getting the dummy variables for landcover classes...\n",
      "Getting the 'mode' landcover classes for source and target...\n",
      "Getting the dummy variables for 'mode' landcover classes...\n",
      "Getting the landcover 'distance'...\n",
      "Feature computation took 20.947s\n"
     ]
    }
   ],
   "source": [
    "### TEST DATA PREPARATION : ONCE outside the loop ###\n",
    "df_pos_test = mu.prepare_positives_from_ids(test_gn_ids, ground_truth_dict, verbose=True)\n",
    "# trim geonames\n",
    "geonames_test = geonames[geonames['geonameid'].isin(test_gn_ids)]\n",
    "df_geonames_test = geonames_test.set_index('geonameid')\n",
    "# candidate selection\n",
    "candidate_selecter = ml.CandidateSelecter(gazetteer_source=df_geonames_test, gazetteer_target=swissnames)\n",
    "matches_test = candidate_selecter.get_candidates_geoleven(id_list=test_gn_ids, matches_per_record=M_test)\n",
    "# turn matches dict into list of pos and neg matches\n",
    "pos_test, neg_test = mu.split_pos_neg(matches_test, ground_truth_dict)\n",
    "pos_test_uniques = list(set(pos_test))\n",
    "print(\"We had %s positive and %s negative pairs retained in candidate selection.\" %(len(pos_test_uniques), len(neg_test)))\n",
    "print(\"We kept %s out of a possible %s positive pairs, i.e. %.3f (upper bound on recall).\" \n",
    "  %(len(pos_test_uniques), df_pos_test.shape[0], len(pos_test_uniques)/df_pos_test.shape[0]))\n",
    "# recall upper bound proper, with original uuids\n",
    "recall_upper_bound = mu.calculate_recall_upper_bound(pos_test_uniques,df_pos_test)\n",
    "# prepare negatives as dataframe\n",
    "df_neg_test_all = pd.DataFrame.from_records(neg_test, columns=['geonamesid', 'swissnamesid', 'match'])\n",
    "df_neg_test = df_neg_test_all.drop_duplicates()\n",
    "# prepare the test matches using all (pos+neg) matches obtained from candidate selection\n",
    "df_test_pos = pd.DataFrame.from_records(pos_test_uniques, columns=['geonamesid', 'swissnamesid', 'match'])\n",
    "df_test = df_test_pos.append(df_neg_test)\n",
    "vc = df_test['match'].value_counts()\n",
    "print(\"Test set: the ratio of neg to pos is %.3f\" %(vc[mu.NO_MATCH_STRING]/vc[mu.MATCH_STRING]))\n",
    "\n",
    "### MATCHING FEATURES FOR TEST DATA : also ONCE outside the loop ###\n",
    "swissnames_test = swissnames[swissnames['UUID'].isin(df_test['swissnamesid'].tolist())]\n",
    "df_swissnames_test = swissnames_test.set_index(['UUID'])\n",
    "fc = ml.FeatureComputer(matches=df_test, gazetteer_source=df_geonames_test, \n",
    "                         gazetteer_target=df_swissnames_test, landcover_data=df_areal, neigh_obj=neighbour_obj)\n",
    "fc.compute_features_all(verbose=True)\n",
    "df_test_all = fc.df.copy()\n",
    "df_test_all['match_bin'] = pd.factorize(df_test_all['match'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare and filter ground truth for new UUIDs...\n",
    "ground_truth_pairs_new_uuids = mu.load_data(path_ground_truth_list_new_uuids)\n",
    "ground_truth_new_uuids_filtered = mu.filter_ground_truth_for_test(ground_truth_pairs_new_uuids, test_gn_ids)\n",
    "# ...and original UUIDs for our results\n",
    "ground_truth_pairs = mu.load_data(path_ground_truth_list)\n",
    "ground_truth_filtered = mu.filter_ground_truth_for_test(ground_truth_pairs, test_gn_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 394 positive matches and 13 records with no match\n",
      "Processing record 0...\n",
      "Processing record 50...\n",
      "Processing record 100...\n",
      "Processing record 150...\n",
      "Processing record 200...\n",
      "Processing record 250...\n",
      "Processing record 300...\n",
      "We had 351 positive and 9224 negative pairs retained in candidate selection.\n",
      "We kept 351 out of a possible 394 positive pairs, i.e. 0.891\n",
      "The actual ratio of neg to pos is 23.406\n",
      "Calculating point-to-point distance between matches...\n",
      "Calculating Levenshtein distance between names...\n",
      "Calculating Levenshtein distance between de-commaed names...\n",
      "Calculating min Levenshtein distance on alternate names...\n",
      "Getting the min Levenshtein distance overall...\n",
      "Calculating the normalized Levenshtein-Damerau distance...\n",
      "Calculating Jaro similarity...\n",
      "Calculating Jaro-Winkler similarity...\n",
      "Getting the absolute elevation distance...\n",
      "Getting the feature types from both gazetteers...\n",
      "Getting the dummy variables for feature types...\n",
      "Getting the landcover classes for source and target...\n",
      "Getting the dummy variables for landcover classes...\n",
      "Getting the 'mode' landcover classes for source and target...\n",
      "Getting the dummy variables for 'mode' landcover classes...\n",
      "Getting the landcover 'distance'...\n",
      "Feature computation took 80.709s\n"
     ]
    }
   ],
   "source": [
    "### PREPARE ALL POTENTIAL TRAINING DATA ###\n",
    "df_pos_train = mu.prepare_positives_from_ids(potential_training_ids, ground_truth_dict, verbose=True)\n",
    "# trim geonames to just stuff in training data\n",
    "geonames_train = geonames[geonames['geonameid'].isin(potential_training_ids)]\n",
    "df_geonames_train = geonames_train.set_index('geonameid')\n",
    "candidate_selecter = ml.CandidateSelecter(gazetteer_source=df_geonames_train, gazetteer_target=swissnames)\n",
    "matches_train = candidate_selecter.get_candidates_geoleven(id_list=potential_training_ids, matches_per_record=M_train)\n",
    "# turn matches dict into list of pos (if any) and neg matches\n",
    "pos_train, neg_train = mu.split_pos_neg(matches_train, ground_truth_dict)\n",
    "pos_train_uniques = list(set(pos_train))\n",
    "print(\"We had %s positive and %s negative pairs retained in candidate selection.\" %(len(pos_train_uniques), len(neg_train)))\n",
    "print(\"We kept %s out of a possible %s positive pairs, i.e. %.3f\" \n",
    "  %(len(pos_train_uniques), df_pos_train.shape[0], len(pos_train_uniques)/df_pos_train.shape[0]))\n",
    "# prepare negatives from the ones mined\n",
    "df_neg_train_all = pd.DataFrame.from_records(neg_train, columns=['geonamesid', 'swissnamesid', 'match'])\n",
    "df_neg_train = df_neg_train_all.drop_duplicates()\n",
    "# take all positives from ground truth (not just ones mined) and combine with negs\n",
    "df_train = df_pos_train.append(df_neg_train)\n",
    "# actual ratio of neg to pos in final training set\n",
    "vc = df_train['match'].value_counts()\n",
    "print(\"The actual ratio of neg to pos is %.3f\" %(vc[mu.NO_MATCH_STRING]/vc[mu.MATCH_STRING]))\n",
    "\n",
    "### MATCHING FEATURES FOR TRAINING DATA ###\n",
    "# trim swissnames to just records that appear in training data\n",
    "swissnames_train = swissnames[swissnames['UUID'].isin(df_train['swissnamesid'].tolist())]\n",
    "df_swissnames_train = swissnames_train.set_index(['UUID'])\n",
    "# compute matching features\n",
    "fc = ml.FeatureComputer(matches=df_train, gazetteer_source=df_geonames_train, \n",
    "                        gazetteer_target=df_swissnames_train, landcover_data=df_areal, neigh_obj=neighbour_obj)\n",
    "fc.compute_features_all(verbose=True)\n",
    "df_train_full = fc.df.copy()\n",
    "# make another column for integers instead of 'match/no_match'\n",
    "df_train_full['match_bin'] = pd.factorize(df_train_full['match'])[0]\n",
    "\n",
    "### MASSAGE DFs COLUMNS ACROSS TRAIN AND TEST ###\n",
    "for colname in df_test_all.columns:\n",
    "    if colname not in df_train_full.columns:\n",
    "        df_train_full[colname] = 0\n",
    "for colname in df_train_full.columns:\n",
    "    if colname not in df_test_all.columns:\n",
    "        df_test_all[colname] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### training set size 1 ###\n",
      "We have 320 potential ids from which we will sample an extra 40\n",
      "We have 40 training ids for this run\n",
      "We have 1204 pairs for training for this loop.\n",
      "\n",
      "# basic, results:\n",
      "  0.796 precision\n",
      "  0.863 recall\n",
      "  0.828 f1\n",
      "\n",
      "# basic-type, results:\n",
      "  0.844 precision\n",
      "  0.853 recall\n",
      "  0.848 f1\n",
      "\n",
      "# str-type, results:\n",
      "  0.808 precision\n",
      "  0.842 recall\n",
      "  0.825 f1\n",
      "\n",
      "# str-type-lcd, results:\n",
      "  0.810 precision\n",
      "  0.853 recall\n",
      "  0.831 f1\n",
      "\n",
      "### training set size 2 ###\n",
      "We have 280 potential ids from which we will sample an extra 40\n",
      "We have 80 training ids for this run\n",
      "We have 2403 pairs for training for this loop.\n",
      "\n",
      "# basic, results:\n",
      "  0.796 precision\n",
      "  0.821 recall\n",
      "  0.808 f1\n",
      "\n",
      "# basic-type, results:\n",
      "  0.890 precision\n",
      "  0.853 recall\n",
      "  0.871 f1\n",
      "\n",
      "# str-type, results:\n",
      "  0.832 precision\n",
      "  0.884 recall\n",
      "  0.857 f1\n",
      "\n",
      "# str-type-lcd, results:\n",
      "  0.856 precision\n",
      "  0.874 recall\n",
      "  0.865 f1\n",
      "\n",
      "### training set size 3 ###\n",
      "We have 240 potential ids from which we will sample an extra 40\n",
      "We have 120 training ids for this run\n",
      "We have 3598 pairs for training for this loop.\n",
      "\n",
      "# basic, results:\n",
      "  0.798 precision\n",
      "  0.832 recall\n",
      "  0.814 f1\n",
      "\n",
      "# basic-type, results:\n",
      "  0.920 precision\n",
      "  0.853 recall\n",
      "  0.885 f1\n",
      "\n",
      "# str-type, results:\n",
      "  0.856 precision\n",
      "  0.874 recall\n",
      "  0.865 f1\n",
      "\n",
      "# str-type-lcd, results:\n",
      "  0.854 precision\n",
      "  0.863 recall\n",
      "  0.859 f1\n",
      "\n",
      "### training set size 4 ###\n",
      "We have 200 potential ids from which we will sample an extra 40\n",
      "We have 160 training ids for this run\n",
      "We have 4800 pairs for training for this loop.\n",
      "\n",
      "# basic, results:\n",
      "  0.784 precision\n",
      "  0.842 recall\n",
      "  0.812 f1\n",
      "\n",
      "# basic-type, results:\n",
      "  0.910 precision\n",
      "  0.853 recall\n",
      "  0.880 f1\n",
      "\n",
      "# str-type, results:\n",
      "  0.856 precision\n",
      "  0.874 recall\n",
      "  0.865 f1\n",
      "\n",
      "# str-type-lcd, results:\n",
      "  0.856 precision\n",
      "  0.874 recall\n",
      "  0.865 f1\n",
      "\n",
      "### training set size 5 ###\n",
      "We have 160 potential ids from which we will sample an extra 40\n",
      "We have 200 training ids for this run\n",
      "We have 6013 pairs for training for this loop.\n",
      "\n",
      "# basic, results:\n",
      "  0.755 precision\n",
      "  0.842 recall\n",
      "  0.796 f1\n",
      "\n",
      "# basic-type, results:\n",
      "  0.923 precision\n",
      "  0.884 recall\n",
      "  0.903 f1\n",
      "\n",
      "# str-type, results:\n",
      "  0.857 precision\n",
      "  0.884 recall\n",
      "  0.870 f1\n",
      "\n",
      "# str-type-lcd, results:\n",
      "  0.913 precision\n",
      "  0.884 recall\n",
      "  0.898 f1\n",
      "\n",
      "### training set size 6 ###\n",
      "We have 120 potential ids from which we will sample an extra 40\n",
      "We have 240 training ids for this run\n",
      "We have 7211 pairs for training for this loop.\n",
      "\n",
      "# basic, results:\n",
      "  0.800 precision\n",
      "  0.842 recall\n",
      "  0.821 f1\n",
      "\n",
      "# basic-type, results:\n",
      "  0.894 precision\n",
      "  0.884 recall\n",
      "  0.889 f1\n",
      "\n",
      "# str-type, results:\n",
      "  0.874 precision\n",
      "  0.874 recall\n",
      "  0.874 f1\n",
      "\n",
      "# str-type-lcd, results:\n",
      "  0.882 precision\n",
      "  0.863 recall\n",
      "  0.872 f1\n",
      "\n",
      "### training set size 7 ###\n",
      "We have 80 potential ids from which we will sample an extra 40\n",
      "We have 280 training ids for this run\n",
      "We have 8413 pairs for training for this loop.\n",
      "\n",
      "# basic, results:\n",
      "  0.786 precision\n",
      "  0.811 recall\n",
      "  0.798 f1\n",
      "\n",
      "# basic-type, results:\n",
      "  0.874 precision\n",
      "  0.874 recall\n",
      "  0.874 f1\n",
      "\n",
      "# str-type, results:\n",
      "  0.894 precision\n",
      "  0.884 recall\n",
      "  0.889 f1\n",
      "\n",
      "# str-type-lcd, results:\n",
      "  0.902 precision\n",
      "  0.874 recall\n",
      "  0.888 f1\n",
      "\n",
      "### training set size 8 ###\n",
      "We have 40 potential ids from which we will sample an extra 40\n",
      "We have 320 training ids for this run\n",
      "We have 9616 pairs for training for this loop.\n",
      "\n",
      "# basic, results:\n",
      "  0.778 precision\n",
      "  0.811 recall\n",
      "  0.794 f1\n",
      "\n",
      "# basic-type, results:\n",
      "  0.892 precision\n",
      "  0.874 recall\n",
      "  0.883 f1\n",
      "\n",
      "# str-type, results:\n",
      "  0.875 precision\n",
      "  0.884 recall\n",
      "  0.880 f1\n",
      "\n",
      "# str-type-lcd, results:\n",
      "  0.922 precision\n",
      "  0.874 recall\n",
      "  0.897 f1\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "training_size_increment = 40\n",
    "current_training_ids = set()\n",
    "\n",
    "for i in range(8):\n",
    "    print(\"\\n### training set size %s ###\" %(i+1))\n",
    "    potential_extra_ids = potential_training_ids - current_training_ids\n",
    "    print(\"We have %s potential ids from which we will sample an extra 40\" %len(potential_extra_ids))\n",
    "    extra_training_ids = set(random.sample(potential_extra_ids, training_size_increment))\n",
    "    train_gn_ids = current_training_ids.union(extra_training_ids)\n",
    "    print(\"We have %s training ids for this run\" %len(train_gn_ids))\n",
    "    \n",
    "    ### SUBSET OUR TRAINING DATA ###\n",
    "    df_train_all = df_train_full[df_train_full['geonamesid'].isin(train_gn_ids)].copy()\n",
    "    print(\"We have %s pairs for training for this loop.\" %df_train_all.shape[0])\n",
    "\n",
    "    ### RANDOM FOREST ###\n",
    "    # 1) basic\n",
    "    desc = \"basic\"\n",
    "    feature_columns = ['distance', 'leven_min']\n",
    "    X = df_train_all[feature_columns]\n",
    "    y = df_train_all['match_bin']\n",
    "    clf = RandomForestClassifier(n_estimators=200)\n",
    "    clf = clf.fit(X, y)\n",
    "    predictions = clf.predict(df_test_all[feature_columns])\n",
    "    # results\n",
    "    print(\"\\n# %s, results:\" %desc)\n",
    "    pairs = mu.get_positives_as_pairs(df_test_all, predictions)\n",
    "    pairs_old = [(item[0], mu.new_uuid_to_old(item[1])) for item in pairs]\n",
    "    p,r,f1 = mu.evaluate_results_deep(pairs_old, ground_truth_filtered, verbose=True)\n",
    "    results.append((p,r,f1,recall_upper_bound))\n",
    "\n",
    "    # 2) basic-type\n",
    "    desc = \"basic-type\"\n",
    "    cols_to_exclude = ['geonamesid', 'swissnamesid', 'match', 'match_bin', 'leven', 'leven_comma', 'leven_alt', \n",
    "                       'leven_dam_norm', 'jaro', 'jaro_winkler', 'elev_dist', \n",
    "                       'gn_10', 'gn_20', 'gn_30', 'gn_40', 'gn_50', 'gn_60', \n",
    "                       'sn_10', 'sn_20', 'sn_30', 'sn_40', 'sn_50', 'sn_60', \n",
    "                       'gn_mode_10', 'gn_mode_20', 'gn_mode_30', 'gn_mode_40', 'gn_mode_50', 'gn_mode_60', \n",
    "                       'sn_mode_10', 'sn_mode_20', 'sn_mode_30', 'sn_mode_40', 'sn_mode_50', 'sn_mode_60', \n",
    "                       'lc_distance']\n",
    "    feature_columns = [colname for colname in list(df_train_all.columns) if colname not in cols_to_exclude]\n",
    "    X = df_train_all[feature_columns]\n",
    "    y = df_train_all['match_bin']\n",
    "    clf = RandomForestClassifier(n_estimators=200)\n",
    "    clf = clf.fit(X, y)\n",
    "    predictions = clf.predict(df_test_all[feature_columns])\n",
    "    # results\n",
    "    print(\"\\n# %s, results:\" %desc)\n",
    "    pairs = mu.get_positives_as_pairs(df_test_all, predictions)\n",
    "    pairs_old = [(item[0], mu.new_uuid_to_old(item[1])) for item in pairs]\n",
    "    p,r,f1 = mu.evaluate_results_deep(pairs_old, ground_truth_filtered, verbose=True)\n",
    "    results.append((p,r,f1,recall_upper_bound))\n",
    "\n",
    "    # 3) str-type\n",
    "    desc = \"str-type\"\n",
    "    cols_to_exclude = ['geonamesid', 'swissnamesid', 'match', 'match_bin', \n",
    "                       'gn_10', 'gn_20', 'gn_30', 'gn_40', 'gn_50', 'gn_60', \n",
    "                       'sn_10', 'sn_20', 'sn_30', 'sn_40', 'sn_50', 'sn_60', \n",
    "                       'gn_mode_10', 'gn_mode_20', 'gn_mode_30', 'gn_mode_40', 'gn_mode_50', 'gn_mode_60', \n",
    "                       'sn_mode_10', 'sn_mode_20', 'sn_mode_30', 'sn_mode_40', 'sn_mode_50', 'sn_mode_60', \n",
    "                       'elev_dist', 'lc_distance']\n",
    "    feature_columns = [colname for colname in list(df_train_all.columns) if colname not in cols_to_exclude]\n",
    "    X = df_train_all[feature_columns]\n",
    "    y = df_train_all['match_bin']\n",
    "    clf = RandomForestClassifier(n_estimators=200)\n",
    "    clf = clf.fit(X, y)\n",
    "    predictions = clf.predict(df_test_all[feature_columns])\n",
    "    # results\n",
    "    print(\"\\n# %s, results:\" %desc)\n",
    "    pairs = mu.get_positives_as_pairs(df_test_all, predictions)\n",
    "    pairs_old = [(item[0], mu.new_uuid_to_old(item[1])) for item in pairs]\n",
    "    p,r,f1 = mu.evaluate_results_deep(pairs_old, ground_truth_filtered, verbose=True)\n",
    "    results.append((p,r,f1,recall_upper_bound))\n",
    "\n",
    "    # 4) str-type-lcd\n",
    "    desc = \"str-type-lcd\"\n",
    "    cols_to_exclude = ['geonamesid', 'swissnamesid', 'match', 'match_bin', \n",
    "                       'gn_10', 'gn_20', 'gn_30', 'gn_40', 'gn_50', 'gn_60', \n",
    "                       'sn_10', 'sn_20', 'sn_30', 'sn_40', 'sn_50', 'sn_60', \n",
    "                       'gn_mode_10', 'gn_mode_20', 'gn_mode_30', 'gn_mode_40', 'gn_mode_50', 'gn_mode_60', \n",
    "                       'sn_mode_10', 'sn_mode_20', 'sn_mode_30', 'sn_mode_40', 'sn_mode_50', 'sn_mode_60',\n",
    "                       'elev_dist']\n",
    "    feature_columns = [colname for colname in list(df_train_all.columns) if colname not in cols_to_exclude]\n",
    "    X = df_train_all[feature_columns]\n",
    "    y = df_train_all['match_bin']\n",
    "    clf = RandomForestClassifier(n_estimators=200)\n",
    "    clf = clf.fit(X, y)\n",
    "    predictions = clf.predict(df_test_all[feature_columns])\n",
    "    # results\n",
    "    print(\"\\n# %s, results:\" %desc)\n",
    "    pairs = mu.get_positives_as_pairs(df_test_all, predictions)\n",
    "    pairs_old = [(item[0], mu.new_uuid_to_old(item[1])) for item in pairs]\n",
    "    p,r,f1 = mu.evaluate_results_deep(pairs_old, ground_truth_filtered, verbose=True)\n",
    "    results.append((p,r,f1,recall_upper_bound))\n",
    "    \n",
    "    # finally prepare for next loop!\n",
    "    current_training_ids = train_gn_ids.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision\trecall\t\tf1 \t\tmax_recall\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "0.7961   \t0.8632   \t0.8283   \t0.9263\n",
      "0.8438   \t0.8526   \t0.8482   \t0.9263\n",
      "0.8081   \t0.8421   \t0.8247   \t0.9263\n",
      "0.8100   \t0.8526   \t0.8308   \t0.9263\n",
      "0.7959   \t0.8211   \t0.8083   \t0.9263\n",
      "0.8901   \t0.8526   \t0.8710   \t0.9263\n",
      "0.8317   \t0.8842   \t0.8571   \t0.9263\n",
      "0.8557   \t0.8737   \t0.8646   \t0.9263\n",
      "0.7980   \t0.8316   \t0.8144   \t0.9263\n",
      "0.9205   \t0.8526   \t0.8852   \t0.9263\n",
      "0.8557   \t0.8737   \t0.8646   \t0.9263\n",
      "0.8542   \t0.8632   \t0.8586   \t0.9263\n",
      "0.7843   \t0.8421   \t0.8122   \t0.9263\n",
      "0.9101   \t0.8526   \t0.8804   \t0.9263\n",
      "0.8557   \t0.8737   \t0.8646   \t0.9263\n",
      "0.8557   \t0.8737   \t0.8646   \t0.9263\n",
      "0.7547   \t0.8421   \t0.7960   \t0.9263\n",
      "0.9231   \t0.8842   \t0.9032   \t0.9263\n",
      "0.8571   \t0.8842   \t0.8705   \t0.9263\n",
      "0.9130   \t0.8842   \t0.8984   \t0.9263\n",
      "0.8000   \t0.8421   \t0.8205   \t0.9263\n",
      "0.8936   \t0.8842   \t0.8889   \t0.9263\n",
      "0.8737   \t0.8737   \t0.8737   \t0.9263\n",
      "0.8817   \t0.8632   \t0.8723   \t0.9263\n",
      "0.7857   \t0.8105   \t0.7979   \t0.9263\n",
      "0.8737   \t0.8737   \t0.8737   \t0.9263\n",
      "0.8936   \t0.8842   \t0.8889   \t0.9263\n",
      "0.9022   \t0.8737   \t0.8877   \t0.9263\n",
      "0.7778   \t0.8105   \t0.7938   \t0.9263\n",
      "0.8925   \t0.8737   \t0.8830   \t0.9263\n",
      "0.8750   \t0.8842   \t0.8796   \t0.9263\n",
      "0.9222   \t0.8737   \t0.8973   \t0.9263\n"
     ]
    }
   ],
   "source": [
    "print(\"precision\\trecall\\t\\tf1 \\t\\tmax_recall\")\n",
    "print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - \")\n",
    "for p,r,f1,rec_ub in results:\n",
    "    print(\"%.4f   \\t%.4f   \\t%.4f   \\t%.4f\" %(p,r,f1,rec_ub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
