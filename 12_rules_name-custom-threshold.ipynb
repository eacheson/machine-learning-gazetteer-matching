{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule-based gazetteer matching: name-custom-threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "    \n",
    "# own file\n",
    "from gazmatch import matchutils as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468 matching pairs\n"
     ]
    }
   ],
   "source": [
    "# load ground truth data (pickled)\n",
    "ground_truth_flat = mu.load_data(os.path.join(data_dir, 'ground_truth_flat.pkl'))\n",
    "print(\"%s matching pairs\" %len(ground_truth_flat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313562, 21)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load SwissNames3D augmented with lat, lons\n",
    "path_swissnames_csv = os.path.join(data_dir, 'swissnames_new_uuids.csv')\n",
    "swissnames = pd.read_csv(path_swissnames_csv, sep='\\t', encoding='utf-8', low_memory=False)\n",
    "swissnames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source data (Geonames records)\n",
    "path_to_source_data = os.path.join(data_dir, 'source_data_augmented.csv')\n",
    "df_source = pd.read_csv(path_to_source_data, sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings and prep\n",
    "distance_threshold_dict = {\n",
    "    'GLCR':5.0,  # matched types are points in SwissNames\n",
    "    'HLL':5.0,  # matched types are points in SwissNames\n",
    "    'LK':15.0,  # matched type is polygon in SwissNames\n",
    "    'MT':5.0,  # matched types are points in SwissNames\n",
    "    'PASS':5.0,  # matched types are points in SwissNames\n",
    "    'PK':5.0,  # matched types are points in SwissNames\n",
    "    'STM':15.0,  # matched type is line in SwissNames\n",
    "    'VAL':15.0}  # matched type is polygon in SwissNames\n",
    "\n",
    "# swissnames name groups\n",
    "sn_name_groups = swissnames.groupby(['NAME'])\n",
    "\n",
    "# geonames type groups\n",
    "type_groups = df_source.groupby(['feature code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prec\trecall\tf1\n",
      "0.843\t0.861\t0.852\n"
     ]
    }
   ],
   "source": [
    "matches_overall = []\n",
    "neg_overall = []\n",
    "results_type = {}\n",
    "#for file in files:\n",
    "for ftype, group in type_groups:\n",
    "    matches_type = []\n",
    "    neg_type = []\n",
    "    gn_ids_type = []\n",
    "    for index, gn_record in group.iterrows():\n",
    "        name = gn_record['name']\n",
    "        alternatenames = str(gn_record['alternatenames'])\n",
    "        gn_id = gn_record['geonameid']\n",
    "        gn_ids_type.append(gn_id)\n",
    "        # get any exact name matches as candidates, including altnames and the comma-flip trick\n",
    "        df_exact_all = mu.find_all_exact_name_matches(name, alternatenames, sn_name_groups, swissnames)\n",
    "        df_exact = df_exact_all.copy()\n",
    "        if df_exact.empty:\n",
    "            #print(\"Found no exact matches for %s\" %name)\n",
    "            neg_type.append((gn_id, mu.NO_MATCH_STRING))\n",
    "            neg_overall.append((gn_id, mu.NO_MATCH_STRING))\n",
    "            continue\n",
    "        # 2. calculate distance to all exact matches\n",
    "        gn_point = (gn_record['latitude'], gn_record['longitude'])\n",
    "        df_exact['distances'] = df_exact.apply(lambda r: mu.calculate_distance_local(r, gn_point), axis=1)\n",
    "        # 3. take matches within threshold distance as correct\n",
    "        df_subset = df_exact[df_exact['distances'] < distance_threshold_dict[ftype]]\n",
    "        if df_subset.shape[0] > 0:\n",
    "            for sn_id in df_subset['UUID_old'].tolist():\n",
    "                matches_type.append((gn_id, sn_id))\n",
    "                matches_overall.append((gn_id, sn_id))\n",
    "        else:\n",
    "            # no records were below threshold\n",
    "            neg_type.append((gn_id, mu.NO_MATCH_STRING))\n",
    "            neg_overall.append((gn_id, mu.NO_MATCH_STRING))\n",
    "    # filter ground truth to ids of current feature type only\n",
    "    gn_ids_type_set = set(gn_ids_type)\n",
    "    ground_truth_type = [item for item in ground_truth_flat if item[0] in gn_ids_type_set]\n",
    "    results_type[ftype] = mu.evaluate_results_list(matches_type, neg_type, ground_truth_type, verbose=False)\n",
    "\n",
    "print(\"prec\\trecall\\tf1\")\n",
    "p, r, f1 = mu.evaluate_results_list(matches_overall, neg_overall, ground_truth_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Results by type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\tprec\trecall\tf1\n",
      "GLCR\t1.000\t0.966\t0.982\n",
      "HLL\t0.881\t0.981\t0.929\n",
      "LK\t0.773\t0.962\t0.857\n",
      "MT\t0.755\t0.889\t0.816\n",
      "PASS\t0.962\t0.962\t0.962\n",
      "PK\t0.918\t0.938\t0.928\n",
      "STM\t0.672\t0.529\t0.592\n",
      "VAL\t0.750\t0.800\t0.774\n"
     ]
    }
   ],
   "source": [
    "print(\"type\\tprec\\trecall\\tf1\")\n",
    "for k,v in results_type.items():\n",
    "    print(\"%s\\t%.3f\\t%.3f\\t%.3f\" %(k, v[0], v[1], v[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
